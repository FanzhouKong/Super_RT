{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyRetip.retip as retip\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded models/retip_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# trainer = retip.AutoGluonTrainer(to_predict, training_duration=10)\n",
    "# trainer.load_model('models/retip_model.pkl')                                                                                                               \n",
    "# y_pred = trainer.predict(to_predict.get_training_data())\n",
    "# to_predict_raw.insert(3, 'predicted_rt', y_pred)\n",
    "# to_predict_raw['rt_prediction_offset']=abs(to_predict_raw['predicted_rt']-to_predict_raw['rt'])\n",
    "# to_predict_raw.sort_values(by = 'rt_prediction_offset', ascending=False, inplace=True)\n",
    "# to_predict_raw.to_csv('datasets/c18_all_retip_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_descriptors = dataset.get_training_data()\n",
    "# testing_descriptors = dataset.get_validation_data()\n",
    "# training_descriptors.to_csv(os.path.join('mini_dataset', 'train_alc_descriptors.csv'), index = False)\n",
    "# testing_descriptors.to_csv(os.path.join('mini_dataset', 'test_alc_descriptors.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors for training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 322/322 [02:40<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced feature set from 1613 to 817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_raw = pd.read_csv('mini_dataset/test_alc.csv')\n",
    "test_df = retip.Dataset(target_column='rt').load_retip_dataset(\n",
    "    training=test_raw,\n",
    "    # validation=test_raw,\n",
    "    # validation='mini_dataset/test_alc.csv', \n",
    "    # testing='mini_dataset/data_alc.csv'\n",
    "    )\n",
    "test_df.calculate_descriptors(n_proc=6)\n",
    "test_df.preprocess_features('metabolomics')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_size = 1\n",
    "train_raw = pd.read_csv('mini_dataset/train_alc_'+str(partition_size)+'.csv')\n",
    "\n",
    "train_df = retip.Dataset(target_column='rt').load_retip_dataset(\n",
    "    training=train_raw,\n",
    "    # validation=test_raw,\n",
    "    # validation='mini_dataset/test_alc.csv', \n",
    "    # testing='mini_dataset/data_alc.csv'\n",
    "    )\n",
    "train_df.calculate_descriptors(n_proc=6)\n",
    "train_df.preprocess_features('metabolomics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240904_034630\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:30 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T6000\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.59 GB / 16.00 GB (34.9%)\n",
      "Disk Space Avail:   28.06 GB / 460.43 GB (6.1%)\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 30s of the 120s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-09-03 20:46:32,624\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"AutogluonModels/ag-20240904_034630/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Beginning AutoGluon training ... Time limit = 27s\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20240904_034630/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Train Data Rows:    113\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Train Data Columns: 817\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Label Column:       rt\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tAvailable Memory:                    5428.79 MB\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.71 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\t\tNote: Converting 79 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tUseless Original Features (Count: 187): ['nB', 'nBr', 'nI', 'nBondsT', 'C1SP1', 'C2SP1', 'NsLi', 'NssBe', 'NssssBe', 'NssBH', 'NsssB', 'NssssB', 'NdCH2', 'NtCH', 'NddC', 'NtsC', 'NsNH3', 'NssNH2', 'NdNH', 'NtN', 'NsssNH', 'NddsN', 'NsSiH3', 'NssSiH2', 'NsssSiH', 'NsPH2', 'NssPH', 'NsssP', 'NsssssP', 'NsSH', 'NdS', 'NaaS', 'NdssS', 'NsGeH3', 'NssGeH2', 'NsssGeH', 'NssssGe', 'NsAsH2', 'NssAsH', 'NsssAs', 'NsssdAs', 'NsssssAs', 'NsSeH', 'NdSe', 'NssSe', 'NaaSe', 'NdssSe', 'NddssSe', 'NsBr', 'NsSnH3', 'NssSnH2', 'NsssSnH', 'NssssSn', 'NsI', 'NsPbH3', 'NssPbH2', 'NsssPbH', 'NssssPb', 'SsLi', 'SssBe', 'SssssBe', 'SssBH', 'SsssB', 'SssssB', 'SdCH2', 'StCH', 'SddC', 'StsC', 'SsNH3', 'SssNH2', 'SdNH', 'StN', 'SsssNH', 'SddsN', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SsPH2', 'SssPH', 'SsssP', 'SsssssP', 'SsSH', 'SdS', 'SaaS', 'SdssS', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SsssdAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SaaSe', 'SdssSe', 'SddssSe', 'SsBr', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsI', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'SMR_VSA2', 'SMR_VSA8', 'SlogP_VSA9', 'n8Ring', 'n9Ring', 'n10Ring', 'n11Ring', 'n12Ring', 'n8HRing', 'n9HRing', 'n10HRing', 'n11HRing', 'n12HRing', 'n3aRing', 'n4aRing', 'n7aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'n3aHRing', 'n4aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'n8ARing', 'n9ARing', 'n10ARing', 'n11ARing', 'n12ARing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n11AHRing', 'n12AHRing', 'n4FRing', 'n5FRing', 'n6FRing', 'n12FRing', 'n4FHRing', 'n5FHRing', 'n6FHRing', 'n12FHRing', 'nG12FHRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n8FaRing', 'n11FaRing', 'n12FaRing', 'nG12FaRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n8FaHRing', 'n11FaHRing', 'n12FaHRing', 'nG12FaHRing', 'n4FARing', 'n5FARing', 'n6FARing', 'n9FARing', 'n12FARing', 'n4FAHRing', 'n5FAHRing', 'n6FAHRing', 'n9FAHRing', 'n12FAHRing', 'nG12FAHRing']\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tUnused Original Features (Count: 47): ['nBondsA', 'Xch-3dv', 'NsF', 'NdsssP', 'NssS', 'NsCl', 'SsF', 'SssS', 'PEOE_VSA5', 'n3Ring', 'n4Ring', 'nG12Ring', 'n3HRing', 'n4HRing', 'n7HRing', 'nG12HRing', 'n5aRing', 'n5aHRing', 'n3ARing', 'n4ARing', 'n7ARing', 'nG12ARing', 'n3AHRing', 'n4AHRing', 'n7AHRing', 'nG12AHRing', 'n7FRing', 'n11FRing', 'n7FHRing', 'n8FHRing', 'n9FHRing', 'n10FHRing', 'n11FHRing', 'n9FaRing', 'nFaHRing', 'n9FaHRing', 'n10FaHRing', 'n7FARing', 'n8FARing', 'n11FARing', 'nG12FARing', 'n7FAHRing', 'n8FAHRing', 'n10FAHRing', 'n11FAHRing', 'MWC01', 'SRW03']\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\t('float', []) :  6 | ['Xch-3dv', 'SsF', 'SssS', 'PEOE_VSA5', 'MWC01', ...]\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\t('int', [])   : 41 | ['nBondsA', 'NsF', 'NdsssP', 'NssS', 'NsCl', ...]\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\t('float', [])  : 480 | ['ABC', 'ABCGG', 'ATS0dv', 'ATS1dv', 'ATS2dv', ...]\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\t('int', [])    : 101 | ['nAcid', 'nBase', 'nAromAtom', 'nAromBond', 'nAtom', ...]\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\t('object', []) :   2 | ['Lipinski', 'GhoseFilter']\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\t('float', [])     : 478 | ['ABC', 'ABCGG', 'ATS0dv', 'ATS1dv', 'ATS2dv', ...]\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\t('int', [])       :  70 | ['nAcid', 'nAromAtom', 'nAromBond', 'nAtom', 'nHeavyAtom', ...]\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t\t('int', ['bool']) :  35 | ['nBase', 'nSpiro', 'nBridgehead', 'nS', 'nF', ...]\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.4s = Fit runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t583 features in original data used to generate 583 features in processed data.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.48 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Data preprocessing and feature engineering runtime = 0.43s ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting 108 L1 models ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 17.99s of the 26.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-31.252\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 17.13s of the 26.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-29.7135\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 17.04s of the 26.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.96%)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-22.9918\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 15.02s of the 24.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.03%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=9594)\u001b[0m [1000]\tvalid_set's rmse: 14.1777\n",
      "\u001b[36m(_ray_fit pid=9594)\u001b[0m [2000]\tvalid_set's rmse: 13.9257\n",
      "\u001b[36m(_ray_fit pid=9594)\u001b[0m [3000]\tvalid_set's rmse: 13.8803\n",
      "\u001b[36m(_ray_fit pid=9594)\u001b[0m [4000]\tvalid_set's rmse: 13.8737\n",
      "\u001b[36m(_ray_fit pid=9594)\u001b[0m [5000]\tvalid_set's rmse: 13.8723\n",
      "\u001b[36m(_ray_fit pid=9594)\u001b[0m [6000]\tvalid_set's rmse: 13.8719\n",
      "\u001b[36m(_ray_fit pid=9594)\u001b[0m [7000]\tvalid_set's rmse: 13.8718\n",
      "\u001b[36m(_ray_fit pid=9594)\u001b[0m [8000]\tvalid_set's rmse: 13.8718\n",
      "\u001b[36m(_ray_fit pid=9594)\u001b[0m [9000]\tvalid_set's rmse: 13.8718\n",
      "\u001b[36m(_ray_fit pid=9594)\u001b[0m [10000]\tvalid_set's rmse: 13.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-22.0781\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t4.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 9.32s of the 18.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-22.2971\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t1.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 8.19s of the 17.18s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.69%)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-24.2015\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t6.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 0.18s of the 9.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-22.3146\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 26.99s of the 8.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.435, 'RandomForestMSE_BAG_L1': 0.304, 'ExtraTreesMSE_BAG_L1': 0.174, 'LightGBMXT_BAG_L1': 0.087}\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-21.4091\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting 106 L2 models ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 8.32s of the 8.29s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.83%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=9649)\u001b[0m [1000]\tvalid_set's rmse: 30.4385\n",
      "\u001b[36m(_ray_fit pid=9647)\u001b[0m [1000]\tvalid_set's rmse: 15.1292\n",
      "\u001b[36m(_ray_fit pid=9647)\u001b[0m [2000]\tvalid_set's rmse: 15.0353\n",
      "\u001b[36m(_ray_fit pid=9647)\u001b[0m [3000]\tvalid_set's rmse: 15.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-22.127\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t1.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 5.4s of the 5.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.88%)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-21.2813\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 2.76s of the 2.72s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-22.4053\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 1.95s of the 1.91s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.79%)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-43.8392\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t1.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.11s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 26.99s of the -2.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.542, 'LightGBM_BAG_L1': 0.25, 'LightGBMXT_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.083, 'LightGBMXT_BAG_L2': 0.042}\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t-20.79\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m AutoGluon training complete, total runtime = 29.88s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 70.9 rows/s (15 batch size)\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t1.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t1.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting 1 L1 models ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t1.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.435, 'RandomForestMSE_BAG_L1': 0.304, 'ExtraTreesMSE_BAG_L1': 0.174, 'LightGBMXT_BAG_L1': 0.087}\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting 1 L2 models ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.542, 'LightGBM_BAG_L1': 0.25, 'LightGBMXT_BAG_L1': 0.083, 'ExtraTreesMSE_BAG_L1': 0.083, 'LightGBMXT_BAG_L2': 0.042}\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m \t0.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Refit complete, total runtime = 4.34s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240904_034630/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=9563)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   RandomForestMSE_BAG_L2_FULL     -18.404401 -22.405324  root_mean_squared_error        0.325272            NaN  5.336822                 0.028956                0.040449           0.726573            2       True         11\n",
      "1   RandomForestMSE_BAG_L1_FULL     -18.415320 -22.297079  root_mean_squared_error        0.068743       0.039655  1.054335                 0.068743                0.039655           1.054335            1       True          5\n",
      "2        LightGBMXT_BAG_L1_FULL     -18.579121 -22.991824  root_mean_squared_error        0.034302            NaN  0.317222                 0.034302                     NaN           0.317222            1       True          3\n",
      "3     ExtraTreesMSE_BAG_L1_FULL     -18.856976 -22.314640  root_mean_squared_error        0.035272       0.039970  0.590466                 0.035272                0.039970           0.590466            1       True          7\n",
      "4      WeightedEnsemble_L2_FULL     -19.305044 -21.409103  root_mean_squared_error        0.249131            NaN  3.154023                 0.001399                     NaN           0.004163            2       True          8\n",
      "5      WeightedEnsemble_L3_FULL     -20.068195 -20.789989  root_mean_squared_error        0.306101            NaN  5.508822                 0.001325                     NaN           0.004971            3       True         13\n",
      "6          LightGBM_BAG_L2_FULL     -20.392092 -21.281288  root_mean_squared_error        0.300154            NaN  4.838464                 0.003838                     NaN           0.228216            2       True         10\n",
      "7        LightGBMXT_BAG_L2_FULL     -20.768017 -22.127015  root_mean_squared_error        0.300938            NaN  5.275635                 0.004622                     NaN           0.665387            2       True          9\n",
      "8          CatBoost_BAG_L1_FULL     -20.990680 -24.201474  root_mean_squared_error        0.021594            NaN  1.409481                 0.021594                     NaN           1.409481            1       True          6\n",
      "9          LightGBM_BAG_L1_FULL     -21.425572 -22.078135  root_mean_squared_error        0.109415            NaN  1.187837                 0.109415                     NaN           1.187837            1       True          4\n",
      "10   KNeighborsDist_BAG_L1_FULL     -29.501648 -29.713516  root_mean_squared_error        0.015732       0.008499  0.031213                 0.015732                0.008499           0.031213            1       True          2\n",
      "11   KNeighborsUnif_BAG_L1_FULL     -31.401634 -31.251988  root_mean_squared_error        0.011258       0.095434  0.019695                 0.011258                0.095434           0.019695            1       True          1\n",
      "12         CatBoost_BAG_L2_FULL     -40.555112 -43.839221  root_mean_squared_error        0.313851            NaN  4.812304                 0.017535                     NaN           0.202055            2       True         12\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t38s\t = DyStack   runtime |\t82s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 82s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240904_034630\"\n",
      "Train Data Rows:    128\n",
      "Train Data Columns: 817\n",
      "Label Column:       rt\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5786.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.80 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 79 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 187): ['nB', 'nBr', 'nI', 'nBondsT', 'C1SP1', 'C2SP1', 'NsLi', 'NssBe', 'NssssBe', 'NssBH', 'NsssB', 'NssssB', 'NdCH2', 'NtCH', 'NddC', 'NtsC', 'NsNH3', 'NssNH2', 'NdNH', 'NtN', 'NsssNH', 'NddsN', 'NsSiH3', 'NssSiH2', 'NsssSiH', 'NsPH2', 'NssPH', 'NsssP', 'NsssssP', 'NsSH', 'NdS', 'NaaS', 'NdssS', 'NsGeH3', 'NssGeH2', 'NsssGeH', 'NssssGe', 'NsAsH2', 'NssAsH', 'NsssAs', 'NsssdAs', 'NsssssAs', 'NsSeH', 'NdSe', 'NssSe', 'NaaSe', 'NdssSe', 'NddssSe', 'NsBr', 'NsSnH3', 'NssSnH2', 'NsssSnH', 'NssssSn', 'NsI', 'NsPbH3', 'NssPbH2', 'NsssPbH', 'NssssPb', 'SsLi', 'SssBe', 'SssssBe', 'SssBH', 'SsssB', 'SssssB', 'SdCH2', 'StCH', 'SddC', 'StsC', 'SsNH3', 'SssNH2', 'SdNH', 'StN', 'SsssNH', 'SddsN', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SsPH2', 'SssPH', 'SsssP', 'SsssssP', 'SsSH', 'SdS', 'SaaS', 'SdssS', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SsssdAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SaaSe', 'SdssSe', 'SddssSe', 'SsBr', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsI', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'SMR_VSA2', 'SMR_VSA8', 'SlogP_VSA9', 'n8Ring', 'n9Ring', 'n10Ring', 'n11Ring', 'n12Ring', 'n8HRing', 'n9HRing', 'n10HRing', 'n11HRing', 'n12HRing', 'n3aRing', 'n4aRing', 'n7aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'n3aHRing', 'n4aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'n8ARing', 'n9ARing', 'n10ARing', 'n11ARing', 'n12ARing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n11AHRing', 'n12AHRing', 'n4FRing', 'n5FRing', 'n6FRing', 'n12FRing', 'n4FHRing', 'n5FHRing', 'n6FHRing', 'n12FHRing', 'nG12FHRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n8FaRing', 'n11FaRing', 'n12FaRing', 'nG12FaRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n8FaHRing', 'n11FaHRing', 'n12FaHRing', 'nG12FaHRing', 'n4FARing', 'n5FARing', 'n6FARing', 'n9FARing', 'n12FARing', 'n4FAHRing', 'n5FAHRing', 'n6FAHRing', 'n9FAHRing', 'n12FAHRing', 'nG12FAHRing']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 47): ['nBondsA', 'Xch-3dv', 'NsF', 'NdsssP', 'NssS', 'NsCl', 'SsF', 'SssS', 'PEOE_VSA5', 'n3Ring', 'n4Ring', 'nG12Ring', 'n3HRing', 'n4HRing', 'n7HRing', 'nG12HRing', 'n5aRing', 'n5aHRing', 'n3ARing', 'n4ARing', 'n7ARing', 'nG12ARing', 'n3AHRing', 'n4AHRing', 'n7AHRing', 'nG12AHRing', 'n7FRing', 'n11FRing', 'n7FHRing', 'n8FHRing', 'n9FHRing', 'n10FHRing', 'n11FHRing', 'n9FaRing', 'nFaHRing', 'n9FaHRing', 'n10FaHRing', 'n7FARing', 'n8FARing', 'n11FARing', 'nG12FARing', 'n7FAHRing', 'n8FAHRing', 'n10FAHRing', 'n11FAHRing', 'MWC01', 'SRW03']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) :  6 | ['Xch-3dv', 'SsF', 'SssS', 'PEOE_VSA5', 'MWC01', ...]\n",
      "\t\t('int', [])   : 41 | ['nBondsA', 'NsF', 'NdsssP', 'NssS', 'NsCl', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 480 | ['ABC', 'ABCGG', 'ATS0dv', 'ATS1dv', 'ATS2dv', ...]\n",
      "\t\t('int', [])    : 101 | ['nAcid', 'nBase', 'nAromAtom', 'nAromBond', 'nAtom', ...]\n",
      "\t\t('object', []) :   2 | ['Lipinski', 'GhoseFilter']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 478 | ['ABC', 'ABCGG', 'ATS0dv', 'ATS1dv', 'ATS2dv', ...]\n",
      "\t\t('int', [])       :  70 | ['nAcid', 'nAromAtom', 'nAromBond', 'nAtom', 'nHeavyAtom', ...]\n",
      "\t\t('int', ['bool']) :  35 | ['nBase', 'nSpiro', 'nBridgehead', 'nS', 'nF', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t583 features in original data used to generate 583 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.54 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.45s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 81.22s of the 81.21s of remaining time.\n",
      "\t-30.5085\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 80.31s of the 80.31s of remaining time.\n",
      "\t-28.9085\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 80.17s of the 80.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.84%)\n",
      "\t-21.1239\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 77.11s of the 77.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.03%)\n",
      "\t-22.9438\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 74.58s of the 74.57s of remaining time.\n",
      "\t-21.9183\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 73.63s of the 73.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.75%)\n",
      "\t-21.8045\t = Validation score   (-root_mean_squared_error)\n",
      "\t58.93s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 12.86s of the 12.86s of remaining time.\n",
      "\t-21.6765\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 12.27s of the 12.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
      "\t-20.7196\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.61s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 8.08s of the 8.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.44%)\n",
      "\t-23.2385\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.93s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1.92s of the 1.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "2024-09-03 20:48:33,483\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-09-03 20:48:33,484\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-09-03 20:48:33,486\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-09-03 20:48:33,487\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-09-03 20:48:33,492\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 81.22s of the -3.08s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.478, 'XGBoost_BAG_L1': 0.261, 'LightGBMXT_BAG_L1': 0.217, 'ExtraTreesMSE_BAG_L1': 0.043}\n",
      "\t-19.3023\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 84.78s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 199.8 rows/s (16 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t1.04s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.32s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t6.81s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 22.\n",
      "\t0.7s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.92s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.478, 'XGBoost_BAG_L1': 0.261, 'LightGBMXT_BAG_L1': 0.217, 'ExtraTreesMSE_BAG_L1': 0.043}\n",
      "\t0.01s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 10.29s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240904_034630\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 0:02:13.510924 with best RMSE 19.302\n"
     ]
    }
   ],
   "source": [
    "trainer = retip.AutoGluonTrainer(train_df, training_duration=2)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trainer.predict(test_df.get_training_data())\n",
    "# y_pred[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.015189274832675"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "from sklearn.metrics import mean_squared_error \n",
    "np.sqrt(mean_squared_error(test_df.get_training_data()['rt'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors for training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [03:12<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced feature set from 1613 to 817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "partition_size = 3\n",
    "train_raw = pd.read_csv('mini_dataset/train_alc_'+str(partition_size)+'.csv')\n",
    "\n",
    "train_df = retip.Dataset(target_column='rt').load_retip_dataset(\n",
    "    training=train_raw,\n",
    "    # validation=test_raw,\n",
    "    # validation='mini_dataset/test_alc.csv', \n",
    "    # testing='mini_dataset/data_alc.csv'\n",
    "    )\n",
    "train_df.calculate_descriptors(n_proc=6)\n",
    "train_df.preprocess_features('metabolomics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(train_df.get_training_data().drop(columns='rt').values, train_df.get_training_data()['rt'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(test_df.get_training_data().drop(columns='rt').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.906120615221173"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(test_df.get_training_data()['rt'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.572106366939678\n"
     ]
    }
   ],
   "source": [
    "offset = abs(test_df.get_training_data()['rt']-y_pred)\n",
    "print(np.median(offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c18_all.to_csv(os.path.join('mini_dataset', 'data_alc_retip_predicted.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved AutoGluon model to models/retip_model.pkl\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('models/retip_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded models/retip_model.pkl\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyretip",
   "language": "python",
   "name": "pyretip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
